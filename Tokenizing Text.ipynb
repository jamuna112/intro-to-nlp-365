{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tokenizing Text\n",
    "\n",
    "Fundamental step in NLP involves converting our text into smaller units through a process known as tokenization. These smaller units are known as our tokens. Word tokenization is the most common form of tokenization, where individual words in the text becomes a token, but token can also be sentences, sub words or individual characters depending on your case."
   ],
   "id": "f53013d689f44d44"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Why do we do this? The meaning of the overall text is better understood if we can analyse and understand the individual  parts as well as the whole. It's also an important step before we vecotrize data.\n",
   "id": "35290e87a1d0ee7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T18:19:48.875206Z",
     "start_time": "2025-07-29T18:19:48.602139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n"
   ],
   "id": "f07f4fce1a6f6459",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/a877544/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T18:19:48.901705Z",
     "start_time": "2025-07-29T18:19:48.900124Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7f91309e0e8d8126",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Sentence tokenization",
   "id": "1464a50173c73098"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T18:19:48.940218Z",
     "start_time": "2025-07-29T18:19:48.919015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentence = \"Her cat's name is Luna. Her dog's name is max\"\n",
    "sent_tokenize(sentence)"
   ],
   "id": "6b871777c9158951",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Her cat's name is Luna.\", \"Her dog's name is max\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Word tokenization",
   "id": "c4c7e404cb812aea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T18:19:48.971340Z",
     "start_time": "2025-07-29T18:19:48.966767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentence = \"Her cat's name is Luna\"\n",
    "word_tokenize(sentence)"
   ],
   "id": "ce5748f8a22fcbae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Her', 'cat', \"'s\", 'name', 'is', 'Luna']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T18:21:03.060174Z",
     "start_time": "2025-07-29T18:21:03.053640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentence_2 = \"Her cat's name is Luna and her dog's name is max\"\n",
    "word_tokenize(sentence_2)"
   ],
   "id": "354c3bd7b17bb386",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Her',\n",
       " 'cat',\n",
       " \"'s\",\n",
       " 'name',\n",
       " 'is',\n",
       " 'Luna',\n",
       " 'and',\n",
       " 'her',\n",
       " 'dog',\n",
       " \"'s\",\n",
       " 'name',\n",
       " 'is',\n",
       " 'max']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
